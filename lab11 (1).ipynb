{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Tweets into MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Python libraries\n",
    "\n",
    "You may need to restart your Jupyter Notebook instance after installed those libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting pymongo\n",
      "  Downloading pymongo-4.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (500 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m500.9/500.9 KB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dnspython<3.0.0,>=1.16.0\n",
      "  Downloading dnspython-2.2.1-py3-none-any.whl (269 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m269.1/269.1 KB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
      "Successfully installed dnspython-2.2.1 pymongo-4.3.2\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: pymongo[srv] in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (4.3.2)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from pymongo[srv]) (2.2.1)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pymongo[srv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: dnspython in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (2.2.1)\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install dnspython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting tweepy\n",
      "  Downloading tweepy-4.12.1-py3-none-any.whl (101 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m101.6/101.6 KB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting oauthlib<4,>=3.2.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m151.7/151.7 KB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-oauthlib<2,>=1.2.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting requests<3,>=2.27.0\n",
      "  Using cached requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests<3,>=2.27.0->tweepy) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests<3,>=2.27.0->tweepy) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests<3,>=2.27.0->tweepy) (3.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from requests<3,>=2.27.0->tweepy) (2.0.8)\n",
      "Installing collected packages: requests, oauthlib, requests-oauthlib, tweepy\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.26.0\n",
      "    Uninstalling requests-2.26.0:\n",
      "      Successfully uninstalled requests-2.26.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-project 0.10.2 requires ruamel-yaml, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed oauthlib-3.2.2 requests-2.28.1 requests-oauthlib-1.3.1 tweepy-4.12.1\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting twitter\n",
      "  Downloading twitter-1.19.6-py2.py3-none-any.whl (50 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.3/50.3 KB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.8/site-packages (from twitter) (2021.10.8)\n",
      "Installing collected packages: twitter\n",
      "Successfully installed twitter-1.19.6\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import json\n",
    "import tweepy\n",
    "import twitter\n",
    "from pprint import pprint\n",
    "import configparser\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Load the Authorization Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save database connection info and API Keys in a config.ini file and use the configparse to load the authorization info. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "CONSUMER_KEY      = config['mytwitter']['api_key']\n",
    "CONSUMER_SECRET   = config['mytwitter']['api_secrete']\n",
    "OAUTH_TOKEN       = config['mytwitter']['access_token']\n",
    "OATH_TOKEN_SECRET = config['mytwitter']['access_secrete']\n",
    "\n",
    "mongod_connect = config['mymongo']['connection']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the MongoDB Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id_1'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient(mongod_connect)\n",
    "db = client.demo # use or create a database named demo\n",
    "tweet_collection = db.lab11 #use or create a collection named tweet_collection\n",
    "tweet_collection.create_index([(\"id\", pymongo.ASCENDING)],unique = True) # make sure the collected tweets are unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Streaming API to Collect Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authorize the Stream API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "stream_auth.set_access_token(OAUTH_TOKEN, OATH_TOKEN_SECRET)\n",
    "\n",
    "strem_api = tweepy.API(stream_auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the query for the Stream API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "track = ['election'] # define the keywords, tweets contain election\n",
    "\n",
    "locations = [-78.9326449,38.4150904,-78.8816972,38.4450731] #defin the location, in Harrisonburg, VA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collected tweets will contain 'election' <span style=\"color:red;font-weight:bold\"> OR </span> are located in Harrisonburg, VA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    def on_status(self, status):\n",
    "        print (status.id_str)\n",
    "        try:\n",
    "            tweet_collection.insert_one(status._json)\n",
    "        except:\n",
    "            pass\n",
    "  \n",
    "    def on_error(self, status_code):\n",
    "        if status_code == 420:\n",
    "            #returning False in on_data disconnects the stream\n",
    "            return False\n",
    "myStreamListener = MyStreamListener()\n",
    "myStream = tweepy.Stream(auth = strem_api.auth, listener=myStreamListener)\n",
    "myStream.filter(track=track)#  (locations = locations)   #Use either track or locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the REST API to Collect Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authorize the REST API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_auth = twitter.oauth.OAuth(OAUTH_TOKEN,OATH_TOKEN_SECRET,CONSUMER_KEY,CONSUMER_SECRET)\n",
    "rest_api = twitter.Twitter(auth=rest_auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the query for the REST API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 100 #number of returned tweets, default and max is 100\n",
    "geocode = \"37.5247764,-77.5633011,150mi\"  # defin the location, in Harrisonburg, VA\n",
    "q = \"covid19\"                               #define the keywords, tweets contain election"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The collected tweets will contain 'election' <span style=\"color:red;font-weight:bold\"> AND </span> are located in Harrisonburg, VA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Thu Nov 17 20:45:11 +0000 2022'\n",
      "'Thu Nov 17 20:45:00 +0000 2022'\n",
      "'Thu Nov 17 20:24:19 +0000 2022'\n",
      "'Thu Nov 17 20:19:38 +0000 2022'\n",
      "'Thu Nov 17 20:15:22 +0000 2022'\n",
      "'Thu Nov 17 20:05:10 +0000 2022'\n",
      "'Thu Nov 17 20:00:05 +0000 2022'\n",
      "'Thu Nov 17 19:50:17 +0000 2022'\n",
      "'Thu Nov 17 19:49:44 +0000 2022'\n",
      "'Thu Nov 17 19:48:27 +0000 2022'\n",
      "'Thu Nov 17 19:48:16 +0000 2022'\n",
      "'Thu Nov 17 19:44:59 +0000 2022'\n",
      "'Thu Nov 17 19:42:25 +0000 2022'\n",
      "'Thu Nov 17 19:33:33 +0000 2022'\n",
      "'Thu Nov 17 19:28:22 +0000 2022'\n",
      "'Thu Nov 17 19:24:21 +0000 2022'\n",
      "'Thu Nov 17 19:14:08 +0000 2022'\n",
      "'Thu Nov 17 19:12:48 +0000 2022'\n",
      "'Thu Nov 17 19:05:10 +0000 2022'\n",
      "'Thu Nov 17 19:01:13 +0000 2022'\n",
      "'Thu Nov 17 19:01:11 +0000 2022'\n",
      "'Thu Nov 17 19:00:01 +0000 2022'\n",
      "'Thu Nov 17 18:57:21 +0000 2022'\n",
      "'Thu Nov 17 18:45:58 +0000 2022'\n",
      "'Thu Nov 17 18:43:28 +0000 2022'\n",
      "'Thu Nov 17 18:37:43 +0000 2022'\n",
      "'Thu Nov 17 18:35:08 +0000 2022'\n",
      "'Thu Nov 17 18:34:00 +0000 2022'\n",
      "'Thu Nov 17 18:31:11 +0000 2022'\n",
      "'Thu Nov 17 18:30:01 +0000 2022'\n",
      "'Thu Nov 17 18:25:05 +0000 2022'\n",
      "'Thu Nov 17 18:24:17 +0000 2022'\n",
      "'Thu Nov 17 18:17:21 +0000 2022'\n",
      "'Thu Nov 17 18:15:49 +0000 2022'\n",
      "'Thu Nov 17 18:11:01 +0000 2022'\n",
      "'Thu Nov 17 18:10:36 +0000 2022'\n",
      "'Thu Nov 17 18:06:30 +0000 2022'\n",
      "'Thu Nov 17 18:01:07 +0000 2022'\n",
      "'Thu Nov 17 18:01:07 +0000 2022'\n",
      "'Thu Nov 17 17:59:22 +0000 2022'\n",
      "'Thu Nov 17 17:54:14 +0000 2022'\n",
      "'Thu Nov 17 17:54:00 +0000 2022'\n",
      "'Thu Nov 17 17:49:00 +0000 2022'\n",
      "'Thu Nov 17 17:39:00 +0000 2022'\n",
      "'Thu Nov 17 17:30:09 +0000 2022'\n",
      "'Thu Nov 17 17:17:24 +0000 2022'\n",
      "'Thu Nov 17 17:15:47 +0000 2022'\n",
      "'Thu Nov 17 17:12:56 +0000 2022'\n",
      "'Thu Nov 17 17:04:06 +0000 2022'\n",
      "'Thu Nov 17 17:03:40 +0000 2022'\n",
      "'Thu Nov 17 17:01:59 +0000 2022'\n",
      "'Thu Nov 17 16:58:24 +0000 2022'\n",
      "'Thu Nov 17 16:38:24 +0000 2022'\n",
      "'Thu Nov 17 16:32:12 +0000 2022'\n",
      "'Thu Nov 17 16:30:24 +0000 2022'\n",
      "'Thu Nov 17 16:28:10 +0000 2022'\n",
      "'Thu Nov 17 16:18:04 +0000 2022'\n",
      "'Thu Nov 17 16:13:29 +0000 2022'\n",
      "'Thu Nov 17 16:05:37 +0000 2022'\n",
      "'Thu Nov 17 16:05:10 +0000 2022'\n",
      "'Thu Nov 17 16:00:46 +0000 2022'\n",
      "'Thu Nov 17 15:50:34 +0000 2022'\n",
      "'Thu Nov 17 15:45:28 +0000 2022'\n",
      "'Thu Nov 17 15:40:17 +0000 2022'\n",
      "'Thu Nov 17 15:39:48 +0000 2022'\n",
      "'Thu Nov 17 15:38:35 +0000 2022'\n",
      "'Thu Nov 17 15:38:00 +0000 2022'\n",
      "'Thu Nov 17 15:32:00 +0000 2022'\n",
      "'Thu Nov 17 15:19:01 +0000 2022'\n",
      "'Thu Nov 17 15:06:23 +0000 2022'\n",
      "'Thu Nov 17 15:05:16 +0000 2022'\n",
      "'Thu Nov 17 15:05:09 +0000 2022'\n",
      "'Thu Nov 17 15:01:47 +0000 2022'\n",
      "'Thu Nov 17 15:00:51 +0000 2022'\n",
      "'Thu Nov 17 15:00:18 +0000 2022'\n",
      "'Thu Nov 17 15:00:03 +0000 2022'\n",
      "'Thu Nov 17 14:56:20 +0000 2022'\n",
      "'Thu Nov 17 14:50:47 +0000 2022'\n",
      "'Thu Nov 17 14:50:41 +0000 2022'\n",
      "'Thu Nov 17 14:41:54 +0000 2022'\n",
      "'Thu Nov 17 14:25:34 +0000 2022'\n",
      "'Thu Nov 17 14:15:47 +0000 2022'\n",
      "'Thu Nov 17 14:14:06 +0000 2022'\n",
      "'Thu Nov 17 14:08:55 +0000 2022'\n",
      "'Thu Nov 17 14:00:02 +0000 2022'\n",
      "'Thu Nov 17 14:00:00 +0000 2022'\n",
      "'Thu Nov 17 13:55:51 +0000 2022'\n",
      "'Thu Nov 17 13:47:36 +0000 2022'\n",
      "'Thu Nov 17 13:35:15 +0000 2022'\n",
      "'Thu Nov 17 13:33:14 +0000 2022'\n",
      "'Thu Nov 17 13:33:00 +0000 2022'\n",
      "'Thu Nov 17 13:31:37 +0000 2022'\n",
      "'Thu Nov 17 13:27:05 +0000 2022'\n",
      "'Thu Nov 17 13:27:00 +0000 2022'\n",
      "'Thu Nov 17 13:14:00 +0000 2022'\n",
      "'Thu Nov 17 13:00:56 +0000 2022'\n",
      "'Thu Nov 17 13:00:01 +0000 2022'\n",
      "'Thu Nov 17 12:06:04 +0000 2022'\n",
      "'Thu Nov 17 12:06:01 +0000 2022'\n",
      "'Thu Nov 17 12:01:47 +0000 2022'\n"
     ]
    }
   ],
   "source": [
    "search_results = rest_api.search.tweets( count=count,q=q, geocode=geocode) #you can use both q and geocode\n",
    "statuses = search_results[\"statuses\"]\n",
    "since_id_new = statuses[-1]['id']\n",
    "for statuse in statuses:\n",
    "    try:\n",
    "        tweet_collection.insert_one(statuse)\n",
    "        pprint(statuse['created_at'])# print the date of the collected tweets\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Continue fetching early tweets with the same query. \n",
    "<p><span style=\"color:red;font-weight:bold\">YOU WILL REACH YOUR RATE LIMIT VERY FAST</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Thu Nov 10 15:37:53 +0000 2022'\n",
      "'Thu Nov 10 15:26:07 +0000 2022'\n",
      "'Thu Nov 10 15:24:44 +0000 2022'\n",
      "'Thu Nov 10 15:15:07 +0000 2022'\n",
      "'Thu Nov 10 15:12:27 +0000 2022'\n",
      "'Thu Nov 10 15:07:35 +0000 2022'\n",
      "'Thu Nov 10 15:04:09 +0000 2022'\n",
      "'Thu Nov 10 15:02:28 +0000 2022'\n",
      "'Thu Nov 10 14:51:53 +0000 2022'\n",
      "'Thu Nov 10 14:35:01 +0000 2022'\n",
      "'Thu Nov 10 14:29:33 +0000 2022'\n",
      "'Thu Nov 10 14:26:29 +0000 2022'\n",
      "'Thu Nov 10 14:20:27 +0000 2022'\n",
      "'Thu Nov 10 14:05:04 +0000 2022'\n",
      "'Thu Nov 10 14:00:01 +0000 2022'\n",
      "'Thu Nov 10 14:00:00 +0000 2022'\n",
      "'Thu Nov 10 13:46:14 +0000 2022'\n",
      "'Thu Nov 10 13:30:00 +0000 2022'\n",
      "'Thu Nov 10 13:23:39 +0000 2022'\n",
      "'Thu Nov 10 13:17:24 +0000 2022'\n",
      "'Thu Nov 10 13:14:12 +0000 2022'\n",
      "'Thu Nov 10 13:02:52 +0000 2022'\n",
      "'Thu Nov 10 13:02:50 +0000 2022'\n",
      "'Thu Nov 10 13:00:04 +0000 2022'\n",
      "'Thu Nov 10 12:24:54 +0000 2022'\n",
      "'Thu Nov 10 12:12:11 +0000 2022'\n",
      "'Thu Nov 10 12:00:58 +0000 2022'\n",
      "'Thu Nov 10 11:13:11 +0000 2022'\n",
      "'Thu Nov 10 10:55:47 +0000 2022'\n",
      "'Thu Nov 10 10:30:06 +0000 2022'\n",
      "'Thu Nov 10 10:30:04 +0000 2022'\n",
      "'Thu Nov 10 10:30:04 +0000 2022'\n",
      "'Thu Nov 10 10:30:03 +0000 2022'\n",
      "'Thu Nov 10 10:27:30 +0000 2022'\n",
      "'Thu Nov 10 09:21:58 +0000 2022'\n",
      "'Thu Nov 10 07:35:19 +0000 2022'\n",
      "'Thu Nov 10 07:33:05 +0000 2022'\n",
      "'Thu Nov 10 05:48:07 +0000 2022'\n",
      "'Thu Nov 10 05:32:24 +0000 2022'\n",
      "'Thu Nov 10 04:59:11 +0000 2022'\n",
      "'Thu Nov 10 04:55:36 +0000 2022'\n",
      "'Thu Nov 10 03:28:43 +0000 2022'\n",
      "'Thu Nov 10 03:00:18 +0000 2022'\n",
      "'Thu Nov 10 01:53:13 +0000 2022'\n",
      "'Thu Nov 10 01:40:07 +0000 2022'\n",
      "'Thu Nov 10 01:36:55 +0000 2022'\n",
      "'Thu Nov 10 00:17:29 +0000 2022'\n",
      "'Thu Nov 10 00:02:00 +0000 2022'\n",
      "'Wed Nov 09 23:01:01 +0000 2022'\n",
      "'Wed Nov 09 22:48:51 +0000 2022'\n",
      "'Wed Nov 09 22:37:43 +0000 2022'\n",
      "'Wed Nov 09 22:05:10 +0000 2022'\n",
      "'Wed Nov 09 22:04:46 +0000 2022'\n",
      "'Wed Nov 09 22:00:35 +0000 2022'\n",
      "'Wed Nov 09 21:51:01 +0000 2022'\n",
      "'Wed Nov 09 21:36:41 +0000 2022'\n",
      "'Wed Nov 09 21:32:26 +0000 2022'\n",
      "'Wed Nov 09 21:01:52 +0000 2022'\n",
      "'Wed Nov 09 21:00:13 +0000 2022'\n",
      "'Wed Nov 09 21:00:06 +0000 2022'\n",
      "'Wed Nov 09 21:00:04 +0000 2022'\n",
      "'Wed Nov 09 20:55:01 +0000 2022'\n",
      "'Wed Nov 09 20:17:47 +0000 2022'\n",
      "'Wed Nov 09 20:05:57 +0000 2022'\n",
      "'Wed Nov 09 20:01:06 +0000 2022'\n",
      "'Wed Nov 09 19:30:06 +0000 2022'\n",
      "'Wed Nov 09 19:30:02 +0000 2022'\n",
      "'Wed Nov 09 19:28:07 +0000 2022'\n",
      "'Wed Nov 09 19:15:00 +0000 2022'\n",
      "'Wed Nov 09 19:03:19 +0000 2022'\n",
      "'Wed Nov 09 19:03:16 +0000 2022'\n",
      "'Wed Nov 09 19:01:26 +0000 2022'\n",
      "'Wed Nov 09 18:54:38 +0000 2022'\n",
      "'Wed Nov 09 18:32:00 +0000 2022'\n",
      "'Wed Nov 09 18:24:52 +0000 2022'\n",
      "'Wed Nov 09 18:24:01 +0000 2022'\n",
      "'Wed Nov 09 18:10:10 +0000 2022'\n",
      "'Wed Nov 09 18:00:21 +0000 2022'\n",
      "'Wed Nov 09 17:59:34 +0000 2022'\n",
      "'Wed Nov 09 17:56:00 +0000 2022'\n",
      "'Wed Nov 09 17:30:14 +0000 2022'\n",
      "'Wed Nov 09 17:28:44 +0000 2022'\n",
      "'Wed Nov 09 17:24:14 +0000 2022'\n",
      "'Wed Nov 09 17:19:05 +0000 2022'\n",
      "'Wed Nov 09 17:18:05 +0000 2022'\n",
      "'Wed Nov 09 17:13:02 +0000 2022'\n",
      "'Wed Nov 09 17:05:11 +0000 2022'\n",
      "'Wed Nov 09 17:04:07 +0000 2022'\n",
      "'Wed Nov 09 17:01:47 +0000 2022'\n",
      "'Wed Nov 09 17:01:08 +0000 2022'\n",
      "'Wed Nov 09 17:00:50 +0000 2022'\n",
      "'Wed Nov 09 17:00:25 +0000 2022'\n",
      "'Wed Nov 09 17:00:11 +0000 2022'\n",
      "'Wed Nov 09 17:00:01 +0000 2022'\n",
      "'Wed Nov 09 16:54:14 +0000 2022'\n",
      "'Wed Nov 09 16:53:38 +0000 2022'\n",
      "'Wed Nov 09 16:50:54 +0000 2022'\n",
      "'Wed Nov 09 16:47:00 +0000 2022'\n",
      "'Wed Nov 09 16:44:41 +0000 2022'\n",
      "'Wed Nov 09 16:40:11 +0000 2022'\n",
      "'Wed Nov 09 16:22:01 +0000 2022'\n",
      "'Wed Nov 09 16:20:10 +0000 2022'\n",
      "'Wed Nov 09 16:10:11 +0000 2022'\n",
      "'Wed Nov 09 16:00:26 +0000 2022'\n",
      "'Wed Nov 09 15:55:54 +0000 2022'\n",
      "'Wed Nov 09 15:45:33 +0000 2022'\n",
      "'Wed Nov 09 15:43:33 +0000 2022'\n",
      "'Wed Nov 09 15:39:55 +0000 2022'\n",
      "'Wed Nov 09 15:30:30 +0000 2022'\n",
      "'Wed Nov 09 15:30:17 +0000 2022'\n",
      "'Wed Nov 09 15:27:43 +0000 2022'\n",
      "'Wed Nov 09 15:27:01 +0000 2022'\n",
      "'Wed Nov 09 15:19:40 +0000 2022'\n",
      "'Wed Nov 09 15:17:30 +0000 2022'\n",
      "'Wed Nov 09 15:16:08 +0000 2022'\n",
      "'Wed Nov 09 15:15:12 +0000 2022'\n",
      "'Wed Nov 09 15:10:45 +0000 2022'\n",
      "'Wed Nov 09 15:10:32 +0000 2022'\n",
      "'Wed Nov 09 15:06:27 +0000 2022'\n",
      "'Wed Nov 09 15:04:41 +0000 2022'\n",
      "'Wed Nov 09 15:04:38 +0000 2022'\n",
      "'Wed Nov 09 15:00:22 +0000 2022'\n",
      "'Wed Nov 09 15:00:03 +0000 2022'\n",
      "'Wed Nov 09 14:41:14 +0000 2022'\n",
      "'Wed Nov 09 14:31:18 +0000 2022'\n",
      "'Wed Nov 09 14:16:46 +0000 2022'\n",
      "'Wed Nov 09 14:05:17 +0000 2022'\n",
      "'Wed Nov 09 14:02:55 +0000 2022'\n",
      "'Wed Nov 09 14:02:01 +0000 2022'\n",
      "'Wed Nov 09 14:00:04 +0000 2022'\n",
      "'Wed Nov 09 14:00:03 +0000 2022'\n",
      "'Wed Nov 09 14:00:02 +0000 2022'\n",
      "'Wed Nov 09 14:00:00 +0000 2022'\n",
      "'Wed Nov 09 13:56:00 +0000 2022'\n",
      "'Wed Nov 09 13:55:42 +0000 2022'\n",
      "'Wed Nov 09 13:55:41 +0000 2022'\n",
      "'Wed Nov 09 13:50:11 +0000 2022'\n",
      "'Wed Nov 09 13:20:12 +0000 2022'\n",
      "'Wed Nov 09 13:00:29 +0000 2022'\n",
      "'Wed Nov 09 13:00:06 +0000 2022'\n",
      "'Wed Nov 09 13:00:04 +0000 2022'\n",
      "'Wed Nov 09 12:49:24 +0000 2022'\n",
      "'Wed Nov 09 12:04:41 +0000 2022'\n",
      "'Wed Nov 09 11:20:33 +0000 2022'\n",
      "'Wed Nov 09 11:12:02 +0000 2022'\n",
      "'Wed Nov 09 10:54:28 +0000 2022'\n",
      "'Wed Nov 09 10:30:06 +0000 2022'\n",
      "'Wed Nov 09 10:30:05 +0000 2022'\n",
      "'Wed Nov 09 08:02:21 +0000 2022'\n",
      "'Wed Nov 09 07:22:57 +0000 2022'\n",
      "'Wed Nov 09 07:02:26 +0000 2022'\n",
      "'Wed Nov 09 06:28:22 +0000 2022'\n",
      "'Wed Nov 09 05:49:51 +0000 2022'\n",
      "'Wed Nov 09 05:36:28 +0000 2022'\n",
      "'Wed Nov 09 05:19:46 +0000 2022'\n",
      "'Wed Nov 09 04:57:41 +0000 2022'\n",
      "'Wed Nov 09 04:40:01 +0000 2022'\n",
      "'Wed Nov 09 04:20:18 +0000 2022'\n",
      "'Wed Nov 09 04:06:27 +0000 2022'\n",
      "'Wed Nov 09 03:38:00 +0000 2022'\n",
      "'Wed Nov 09 03:03:05 +0000 2022'\n",
      "'Wed Nov 09 02:25:39 +0000 2022'\n",
      "'Wed Nov 09 01:57:23 +0000 2022'\n",
      "'Wed Nov 09 01:18:06 +0000 2022'\n",
      "'Wed Nov 09 01:05:03 +0000 2022'\n",
      "'Wed Nov 09 01:00:47 +0000 2022'\n"
     ]
    }
   ],
   "source": [
    "since_id_old = 0\n",
    "while(since_id_new != since_id_old):\n",
    "    since_id_old = since_id_new\n",
    "    search_results = rest_api.search.tweets( count=count,q=q,\n",
    "                        geocode=geocode, max_id= since_id_new)\n",
    "    statuses = search_results[\"statuses\"]\n",
    "    since_id_new = statuses[-1]['id']\n",
    "    for statuse in statuses:\n",
    "        try:\n",
    "            tweet_collection.insert_one(statuse)\n",
    "            pprint(statuse['created_at']) # print the date of the collected tweets\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the Collected Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the number of tweets and unique twitter users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "940\n",
      "501\n"
     ]
    }
   ],
   "source": [
    "print(tweet_collection.estimated_document_count())# number of tweets collected\n",
    "\n",
    "user_cursor = tweet_collection.distinct(\"user.id\")\n",
    "print (len(user_cursor)) # number of unique Twitter users "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a text index and print the Tweets containing specific keywords. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text_index'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_collection.create_index([(\"text\", pymongo.TEXT)], name='text_index', default_language='english') # create a text index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a cursor to query tweets with the created index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_cursor = tweet_collection.find({\"$text\": {\"$search\": \"covid19\"}}) # return tweets contain vote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pprint to display tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----\n",
      "name: University of California Health\n",
      "text: 3/7  9 #COVID19 @UofCAHealth inpatients are on a ventilator. 0 COVID19 inpatients are on extracorporeal membrane ox‚Ä¶ https://t.co/Y4UhTYN0D5\n",
      "----\n",
      "name: Absolut.LIBRA\n",
      "text: Whoopi has #COVID19 #TheView\n",
      "----\n",
      "name: George Robert Martin III aka: \"Nemesis Rising TV\"\n",
      "text: #COVID19 = POPULATION CONTROL AND YOU ALL FELL FOR IT.\n",
      "----\n",
      "name: Paradise Lost CA\n",
      "text: #covid19 https://t.co/6zxWRro0qt\n",
      "----\n",
      "name: Cheryl Cunha\n",
      "text: @mikepompeo And they don't need mandatory Covid19 vaccines.\n",
      "----\n",
      "name: CryDiego\n",
      "text: @SethDillon @MattWalshBlog Just think of the trillions for COVID19\n",
      "----\n",
      "name: ‚ñà‚ñà‚ñà‚ñà Tech Savvy ‚ñà‚ñà‚ñà‚ñà\n",
      "text: #IYKYK #COVID19 https://t.co/TJ3eehZsBu\n",
      "----\n",
      "name: Oscar Cingolani, M.D.\n",
      "text: #COVID19 #covidusa https://t.co/rvFeovbHqN\n",
      "----\n",
      "name: 757 Progressive‚Ñ¢Ô∏èüÜòü¶†üá∫üá∏üåèüî•\n",
      "text: üßµ on the #PermanentPandemic of #COVID19 https://t.co/5JN030xSvM\n",
      "----\n",
      "name: Erik Glasser\n",
      "text: #Simpsons #COVID19 #planned https://t.co/Me6LRnXI3w\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for document in tweet_cursor[0:10]: # display the first 10 tweets from the query\n",
    "    try:\n",
    "        print ('----')\n",
    "#         pprint (document) # use pprint to print the entire tweet document\n",
    "   \n",
    "        print ('name:', document[\"user\"][\"name\"]) # user name\n",
    "        print ('text:', document[\"text\"])         # tweets\n",
    "    except:\n",
    "        print (\"***error in encoding\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_cursor = tweet_collection.find({\"$text\": {\"$search\": \"vote\"}}) # return tweets contain vote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pandas to display tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>entities</th>\n",
       "      <th>metadata</th>\n",
       "      <th>source</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>...</th>\n",
       "      <th>is_quote_status</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>lang</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>quoted_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6376a0fd75cfb81f05556e68</td>\n",
       "      <td>Wed Nov 16 14:48:04 +0000 2022</td>\n",
       "      <td>1592892264019369985</td>\n",
       "      <td>1592892264019369985</td>\n",
       "      <td>Only 1‚É£ week to cast your vote! \\nThe @infobea...</td>\n",
       "      <td>True</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"https://sproutsocial.com\" rel=\"nofoll...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6376a16175cfb81f05557136</td>\n",
       "      <td>Wed Nov 09 11:20:33 +0000 2022</td>\n",
       "      <td>1590303321910575107</td>\n",
       "      <td>1590303321910575107</td>\n",
       "      <td>Look what the fascistic left did to people dur...</td>\n",
       "      <td>True</td>\n",
       "      <td>{'hashtags': [{'text': 'covid19', 'indices': [...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>1.589998e+18</td>\n",
       "      <td>1589997631774011396</td>\n",
       "      <td>{'created_at': 'Tue Nov 08 15:05:50 +0000 2022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6376a0fd75cfb81f05556e8e</td>\n",
       "      <td>Wed Nov 16 01:35:36 +0000 2022</td>\n",
       "      <td>1592692830866055168</td>\n",
       "      <td>1592692830866055168</td>\n",
       "      <td>.@SenateDems, why would you vote to end the #C...</td>\n",
       "      <td>True</td>\n",
       "      <td>{'hashtags': [{'text': 'COVID19', 'indices': [...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>1.592687e+18</td>\n",
       "      <td>1592686727281401856</td>\n",
       "      <td>{'created_at': 'Wed Nov 16 01:11:21 +0000 2022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6376a0fd75cfb81f05556e63</td>\n",
       "      <td>Wed Nov 16 15:05:46 +0000 2022</td>\n",
       "      <td>1592896714654220292</td>\n",
       "      <td>1592896714654220292</td>\n",
       "      <td>Hey @MarkWarner as your constituent who's been...</td>\n",
       "      <td>True</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>1.592804e+18</td>\n",
       "      <td>1592804135401033728</td>\n",
       "      <td>{'created_at': 'Wed Nov 16 08:57:53 +0000 2022...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows √ó 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                      created_at  \\\n",
       "0  6376a0fd75cfb81f05556e68  Wed Nov 16 14:48:04 +0000 2022   \n",
       "1  6376a16175cfb81f05557136  Wed Nov 09 11:20:33 +0000 2022   \n",
       "2  6376a0fd75cfb81f05556e8e  Wed Nov 16 01:35:36 +0000 2022   \n",
       "3  6376a0fd75cfb81f05556e63  Wed Nov 16 15:05:46 +0000 2022   \n",
       "\n",
       "                    id               id_str  \\\n",
       "0  1592892264019369985  1592892264019369985   \n",
       "1  1590303321910575107  1590303321910575107   \n",
       "2  1592692830866055168  1592692830866055168   \n",
       "3  1592896714654220292  1592896714654220292   \n",
       "\n",
       "                                                text  truncated  \\\n",
       "0  Only 1‚É£ week to cast your vote! \\nThe @infobea...       True   \n",
       "1  Look what the fascistic left did to people dur...       True   \n",
       "2  .@SenateDems, why would you vote to end the #C...       True   \n",
       "3  Hey @MarkWarner as your constituent who's been...       True   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "1  {'hashtags': [{'text': 'covid19', 'indices': [...   \n",
       "2  {'hashtags': [{'text': 'COVID19', 'indices': [...   \n",
       "3  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "1  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "2  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "3  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "\n",
       "                                              source in_reply_to_status_id  \\\n",
       "0  <a href=\"https://sproutsocial.com\" rel=\"nofoll...                  None   \n",
       "1  <a href=\"https://mobile.twitter.com\" rel=\"nofo...                  None   \n",
       "2  <a href=\"http://twitter.com/download/android\" ...                  None   \n",
       "3  <a href=\"http://twitter.com/download/android\" ...                  None   \n",
       "\n",
       "   ... is_quote_status retweet_count favorite_count favorited retweeted  \\\n",
       "0  ...           False             2              3     False     False   \n",
       "1  ...            True             0              0     False     False   \n",
       "2  ...            True             2              5     False     False   \n",
       "3  ...            True             2              4     False     False   \n",
       "\n",
       "  possibly_sensitive lang quoted_status_id quoted_status_id_str  \\\n",
       "0              False   en              NaN                  NaN   \n",
       "1              False   en     1.589998e+18  1589997631774011396   \n",
       "2              False   en     1.592687e+18  1592686727281401856   \n",
       "3              False   en     1.592804e+18  1592804135401033728   \n",
       "\n",
       "                                       quoted_status  \n",
       "0                                                NaN  \n",
       "1  {'created_at': 'Tue Nov 08 15:05:50 +0000 2022...  \n",
       "2  {'created_at': 'Wed Nov 16 01:11:21 +0000 2022...  \n",
       "3  {'created_at': 'Wed Nov 16 08:57:53 +0000 2022...  \n",
       "\n",
       "[4 rows x 29 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df = pd.DataFrame(list(tweet_cursor ))\n",
    "tweet_df[:10] #display the first 10 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tweet_df[\"favorite_count\"].hist() # create a histogram show the favorite count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
